# Hugging Face API configuration (REQUIRED)
# Get your token from: https://huggingface.co/settings/tokens
# Make sure you have access to: https://huggingface.co/meta-llama/Llama-Prompt-Guard-2-86M
HF_TOKEN=your_huggingface_token_here

# Together API configuration (Optional)
# Required only if using PII_DETECTION scanner
# Get your API key from: https://www.together.ai/
TOGETHER_API_KEY=your_together_api_key_here

# Scanner configuration (Optional)
# Available scanners:
# - PROMPT_GUARD: Detects prompt injection attempts
# - PII_DETECTION: Detects personally identifiable information
# - HIDDEN_ASCII: Detects hidden ASCII characters
# - AGENT_ALIGNMENT: Checks for agent alignment issues
# - CODE_SHIELD: Detects potentially harmful code
# Available roles: USER, ASSISTANT, SYSTEM
LLAMAFIREWALL_SCANNERS={"USER": ["PROMPT_GUARD"]}

# Tokenizer configuration (Optional)
# Set to false to disable tokenizer parallelism
# This can help with memory usage in some environments
TOKENIZERS_PARALLELISM=false

# Python configuration (Optional)
# These are set by default in the Dockerfile
# PYTHONDONTWRITEBYTECODE=1
# PYTHONUNBUFFERED=1
# PYTHONPATH=/app